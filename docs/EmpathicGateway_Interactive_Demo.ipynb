{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 EmpathicGateway: Interactive Backend Demo\n",
        "### _Run the AI Brain of the system right here!_\n",
        "\n",
        "This notebook allows you to execute the core logic of the EmpathicGateway backend. You will:\n",
        "1.  **Initialize** the AI models.\n",
        "2.  **Train** a fresh intent classifier on synthetic data.\n",
        "3.  **Run Inference** on your own text to see Priority and PII masking in action.\n",
        "\n",
        "---\n",
        "### \ud83d\udee0\ufe0f Step 1: Install Dependencies\n",
        "Run this cell to ensure you have the required libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install sentence-transformers scikit-learn pandas joblib transformers numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83e\udde0 Step 2: Define The AI Architecture\n",
        "Here we define the `BertEmbedder` class, which connects our lightweight Logistic Regression to the powerful BERT Language Model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# This is the exact class from backend/train_model.py\n",
        "class BertEmbedder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        print(f\"\ud83d\udce5 Loading BERT ({self.model_name})...\")\n",
        "        self.model = SentenceTransformer(self.model_name)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.model is None:\n",
        "             self.model = SentenceTransformer(self.model_name)\n",
        "        \n",
        "        # Handle inputs\n",
        "        if hasattr(X, 'tolist'): texts = X.tolist()\n",
        "        else: texts = X\n",
        "            \n",
        "        return self.model.encode(texts, show_progress_bar=False)\n",
        "\n",
        "def map_priority(intent):\n",
        "    if intent in ['payment_issue', 'fraud_report', 'stolen_card']: return 1  # CRITICAL\n",
        "    elif intent in ['track_order', 'cancel_order']: return 2                 # HIGH\n",
        "    else: return 3                                                           # NORMAL\n",
        "\n",
        "print(\"\u2705 Architecture Defined!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83c\udf93 Step 3: Train the Model (Live!)\n",
        "We will use the **Synthetic Dataset** strategy directly in this notebook. Notice how we explicitly teach the model about \"Just Browsing\" vs \"Fraud\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Create Training Data\n",
        "data = [\n",
        "    # --- CRITICAL (Priority 1) ---\n",
        "    {\"text\": \"my wallet was stolen\", \"intent\": \"fraud_report\"},\n",
        "    {\"text\": \"someone used my credit card\", \"intent\": \"fraud_report\"},\n",
        "    {\"text\": \"unauthorized charge on my account\", \"intent\": \"payment_issue\"},\n",
        "    {\"text\": \"i need to block my card immediately\", \"intent\": \"stolen_card\"},\n",
        "    \n",
        "    # --- HIGH (Priority 2) ---\n",
        "    {\"text\": \"where is my order\", \"intent\": \"track_order\"},\n",
        "    {\"text\": \"cancel my order please\", \"intent\": \"cancel_order\"},\n",
        "    {\"text\": \"change my shipping address\", \"intent\": \"track_order\"},\n",
        "    \n",
        "    # --- NORMAL (Priority 3) ---\n",
        "    {\"text\": \"hello\", \"intent\": \"greeting\"},\n",
        "    {\"text\": \"just browsing thanks\", \"intent\": \"chit_chat\"},\n",
        "    {\"text\": \"i am just looking around\", \"intent\": \"chit_chat\"},\n",
        "    {\"text\": \"thank you for the help\", \"intent\": \"chit_chat\"},\n",
        "    {\"text\": \"do you have this in blue\", \"intent\": \"product_question\"}\n",
        "]\n",
        "\n",
        "# Multiply data to mimic real training volume\n",
        "df = pd.DataFrame(data * 5)\n",
        "df['priority'] = df['intent'].apply(map_priority)\n",
        "\n",
        "print(f\"\ud83d\udcda Dataset Created: {len(df)} samples\")\n",
        "print(df.head())\n",
        "\n",
        "# 2. Build Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('embedding', BertEmbedder(model_name='all-MiniLM-L6-v2')),\n",
        "    ('classifier', LogisticRegression(C=1.0, max_iter=500))\n",
        "])\n",
        "\n",
        "# 3. Train\n",
        "print(\"\\n\u2699\ufe0f Training Model... (This uses CPU, might take 10-20s)\")\n",
        "pipeline.fit(df['text'], df['intent'])\n",
        "print(\"\u2705 Model Trained Successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udee1\ufe0f Step 4: PII Masking Logic\n",
        "The backend creates a \"Safe Text\" version of every request. Here is the logic:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mask_pii(text):\n",
        "    safe_text = text\n",
        "    detected_types = []\n",
        "    \n",
        "    # 1. Email Regex\n",
        "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "    if re.search(email_pattern, safe_text):\n",
        "        safe_text = re.sub(email_pattern, '[EMAIL]', safe_text)\n",
        "        detected_types.append(\"EMAIL\")\n",
        "        \n",
        "    # 2. Credit Card Regex (Simple 16 digits)\n",
        "    cc_pattern = r'(?:\\d[ -]*?){13,16}'\n",
        "    # Avoid false positives with simple check\n",
        "    matches = re.findall(cc_pattern, safe_text)\n",
        "    for m in matches:\n",
        "        if len(re.sub(r'\\D', '', m)) >= 13:\n",
        "            safe_text = safe_text.replace(m, '[CREDIT_CARD]')\n",
        "            if \"CREDIT_CARD\" not in detected_types: detected_types.append(\"CREDIT_CARD\")\n",
        "            \n",
        "    return safe_text, detected_types\n",
        "\n",
        "print(\"\u2705 PII System Ready.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83c\udfae Step 5: Interactive Demo\n",
        "**Try it yourself!** Change the `text` variable below and run the cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- INPUT YOUR TEXT HERE ---\n",
        "user_input = \"I lost my wallet and my email is murat@test.com\"\n",
        "# ----------------------------\n",
        "\n",
        "# 1. Safety First (PII)\n",
        "safe_input, pii = mask_pii(user_input)\n",
        "\n",
        "# 2. Model Prediction\n",
        "prediction = pipeline.predict([safe_input])[0]\n",
        "probs = pipeline.predict_proba([safe_input])[0]\n",
        "confidence = max(probs)\n",
        "priority = map_priority(prediction)\n",
        "\n",
        "# 3. Visualization\n",
        "priority_map = {1: \"\ud83d\udd34 CRITICAL\", 2: \"\ud83d\udfe0 HIGH\", 3: \"\ud83d\udfe2 NORMAL\"}\n",
        "priority_label = priority_map.get(priority, \"UNKNOWN\")\n",
        "\n",
        "print(f\"\ud83d\udcdd Original: '{user_input}'\")\n",
        "print(f\"\ud83d\udee1\ufe0f Masked:   '{safe_input}'\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"\ud83e\udde0 Intent:   {prediction.upper()}\")\n",
        "print(f\"\ud83d\udea6 Priority: {priority_label}\")\n",
        "print(f\"\ud83d\udcca Conf:     {confidence:.1%}\")\n",
        "\n",
        "if pii:\n",
        "    print(f\"\u26a0\ufe0f PII Detected: {pii}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83e\uddea Validation: The \"Just Browsing\" Test\n",
        "Let's verify our specific fix for the 'Just browsing' edge case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_cases = [\n",
        "    \"Just browsing, thanks!\",\n",
        "    \"I need a refund immediately\",\n",
        "    \"Hello there\",\n",
        "    \"Where is my stuff?\"\n",
        "]\n",
        "\n",
        "print(f\"{'INPUT':<30} | {'INTENT':<15} | {'PRIORITY'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for text in test_cases:\n",
        "    pred = pipeline.predict([text])[0]\n",
        "    prio = map_priority(pred)\n",
        "    label = {1:\"CRITICAL\", 2:\"HIGH\", 3:\"NORMAL\"}[prio]\n",
        "    print(f\"{text:<30} | {pred:<15} | {label}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}